\chapter{Probability Theory}
\label{ch:probability::theory}

% \newcommand{\probfun}{probability measure}
% \newcommand{\Probfun}{Probability measure}
% \newcommand{\ProbFun}{Probability Measure}
% \newcommand{\primevent}{elementary event}

\begin{preamble}
This chapter introduces the basics of discrete probability theory.
\end{preamble}

\section{Probability Spaces}
\label{sec:probability::theory::spaces}


Probability theory is a mathematical study of uncertain situations
such as a dice game.
%
In probability theory, we model a situation with an uncertain \defn{outcome} as an~\defn{experiment} and reason carefully about the likelihood of various outcomes in precise mathematical terms. 
%


\begin{example}
Suppose we have two \emph{fair} dice, meaning that each is equally
likely to land on any of its six sides.  If we toss the dice, what is
the chance that their numbers sum to $4$?  
%
To determine the probability we first notice that there are a total of 
$6 \times 6 = 36$ distinct outcomes.
%
Of these, only three outcomes sum to 4 (1 and 3, 2 and 2,
and 3 and 1).
%
The probability of the event that the number sum up to $4$ is therefore
\begin{equation*}
\frac
{\text{\# of outcomes that sum to}~4}
{\text{\# of total possible outcomes}} 
= 
\frac{3}{36} = \frac{1}{12}
\end{equation*}

\end{example}
%


\begin{gram}[Sample Spaces and Events]
A \defn{sample space} $\SSpace{}$ is an arbitrary and possibly infinite
(but countable) set of possible outcomes of a probabilistic
experiment.   Any experiment will return exactly one outcome from the set.
%
For the dice game, the sample space is the 36 possible outcomes of the
dice, and an experiment (roll of the dice) will return one of them.  
%
An \defn{event} is any subset of $\SSpace$, and
most often representing some property common to multiple outcomes.  
%
For example, an event could correspond to outcomes in which the dice
add to $4$---this subset would be of size $3$.
%
We typically denote events by capital letters from the start
of the alphabet, e.g. $A$, $B$, $C$.
%
We often refer to the individual elements of $\SSpace{}$ as\defn{elementary events}.
%
We assign a probability to each event.
%
Our model for probability is defined as follows.
\end{gram}

\begin{flex}



%%%% Umut:
%% This definition works for countable infinite spaces.
%% The additivity leads to an infinites sum.
%% If there are infinitely many events considered.
%% See for example, Bertsekas's book.


\begin{definition}[Probability Space]
\label{def:probability::theory::probability-space}

 A probability space consists of a \defn{sample space} $\SSpace{}$
 representing the set of possible outcomes, and a \defn{probability
   measure}, which is a function $\probf$ from all subsets of
 $\SSpace{}$ (the \defn{events}) to a probability (real number).
 These must satisfy the following axioms.

\begin{itemize}
\item \textbf{Nonnegativity:} $\prob{A} \in [0,1]$.

\item \textbf{Additivity:} for any two disjoint events $A$ and $B$
  (i.e., $A \cap B = \emptyset$), \[\prob{A \cup B} =
  \prob{A} + \prob{B}~.\]

\item \textbf{Normalization:} $\prob{\SSpace} = 1$.
\end{itemize}
\end{definition}

\begin{note}[Infinite Spaces]
Probability spaces can have countably infinite outcomes.  
%
The additivity rule generalizes to infinite sums, e.g., the probability of the event consisting of the union of infinitely many number of disjoint events is the infinite sum of the probability of each event. 
\end{note}

\begin{note}
When defining the probability space, we have not specified
carefully the exact nature of events, because they
may differ based on the experiment and what we are interested in.
%
We do, however, need to take care when setting up the probabilistic model so that we can  reason about the experiment correctly. 
%
For example, each outcome of the sample space must correspond to one
unique actual outcome of the experiment.  In other words, they must be
mutually exclusive. 
%
Similarly, any actual outcome of the experiment must have a
corresponding representation in the sample space.
\end{note}
\end{flex}

%%%% I (umut) don't think the non-zero assumption is necessary.
%%%%  
%% \begin{gram}
%%   If the probability of each elementary event is non-zero (assumed
%%   throughout this book), then the probability of any event is simply
%%   the sum of the probabilities of its elements:
%%   \[\prob{A} = \sum_{x \in A} \probprim{x}~.\]
%% %  We will use the shorthand $\prob{x}$ instead of \prob{\{x\}}, for $x \in \SSpace{}$.
%% \end{gram}



\begin{example}[Throwing Dice]
\label{ex:probability::theory::dice}

  For our example of throwing two dice, the sample space
  consists of all of the $36$ possible pairs of values of the dice:
\[
\SSpace = \{(1,1),(1,2),\ldots,(2,1),\ldots,(6,6)\}.
\]
%
Each pair in the sample space corresponds to an outcome of the experiment.
%
The outcomes are mutually exclusive and cover all possible outcomes of
the experiment.


For example, having the first dice show up $1$ and the second $4$ is
an outcome and corresponds to  the element $(1,4)$ of the sample space $\Omega$.

The event that the ``the first dice is 3'' corresponds to the
set
\[
\begin{array}{lcl}
  A & = & \csetf{(d_1,d_2) \in \Omega}{d_1 = 3} \\
  & = &  \{(3,1),(3,2),(3,3),(3,4),(3,5),(3,6)\}~.
\end{array}
\]
The event that ``the dice sum to 4'' corresponds to the set
\[
\begin{array}{lcl}
  B & = & \csetf{(d_1,d_2) \in \Omega}{d_1 + d_2 = 4}\\
  & = & \{(1,3),(2,2),(3,1)\}~.
\end{array}
\]

Assuming the dice are unbiased, 
the probability measure is defined by all elementary
events having equal probability, i.e.,
\[
\forall x \in \SSpace,~~~\probprim{x} = \frac{1}{36}.
\]

The probability of the event $A$ (that the first dice
is 3) is thus 
\[
\prob{A} = \sum_{x \in A} \probprim{x} = \frac{6}{36} = \frac{1}{6}. 
\]

If the dice were biased so the probability of a given value is
proportional to that value, then the
probability measure would be
$\probprim{(x,y)} = \frac{x}{21} \times \frac{y}{21}$, and the probability
of the event $B$ (that the dice add to 4) would be
\[
\prob{B} = \sum_{x \in B} \probprim{x} = \frac{1 \times 3 + 2 \times 2
  + 3 \times 1}{21 \times 21} = \frac{10}{441}. 
\]

% \begin{notesonly}
% One way to do these sums in class is no note that (1 + ... + 6) is
% repeated and it adds up to 21.
% \end{notesonly}

\end{example}


\section{Properties of Probability Spaces}
\label{sec:probability::theory::spaces-properties}


Given a probability space, we can prove several properties of
probability measures by using the three axioms that they must satisfy.
%
For example, if for two events $A$ and $B$.  We have
\begin{itemize}
\item if $A \subseteq B$, then  $\prob{A} \le \prob{B}$,
\item $\prob{A \cup B} = \prob{A}  + \prob{B} -  \prob{A \cap B}$.
\end{itemize}


\subsection{The Union Bound}
\label{sec:probability::theory::union-bound}

The union bound, also known as Boole's inequality, is a simple way to
obtain an upper bound on the probability of any of a collection of events
happening.  Specifically for a collection of events
$A_0, A_2, \ldots, A_{n-1}$ the bound is:
\[
\prob{\bigcup_{0 \leq i < n} A_i} \leq \sum_{i=0}^{n-1} \prob{A_i} 
\]
This bound is true unconditionally.
%
To see why the bound holds we note that the elementary events
in the union on the left are all included in the sum on the right
(since the union comes from the same set of events).  
%
In fact they
might be included multiple times in the sum on the right, hence the
inequality.  In fact the sum on the right could add to more than one, in
which case the bound is not useful.  
%
The union bound can be useful in generating high-probability bounds
for algorithms. For example, when the probability of each of $n$
events is very low, e.g. $1/n^5$ and the sum remains very low,
e.g. $1/n^4$.


\subsection{Conditional Probability}
\label{sec:probability::theory::conditional-pr}


Conditional probability allows us to reason about dependencies between
observations.  
%
For example, suppose that  your friend rolled a pair of dice and told
you that they sum up to $6$, what is the probability that one of
dice has come up $1$?  
%
Conditional probability has many practical applications.
%
For example, given that a medical test for a disease comes up
positive, we might want to know  the probability that the patient has the disease. 
%
Or, given that your computer has been working fine for the past 2
years, you might want to know the probability that it will continue
working for one more year.


\begin{definition}[Conditional Probability]
For a given probability space, we define the \defn{conditional
  probability} of an event $A$ given $B$, as the probability of $A$
occurring given that $B$ occurs as
\[
\prob{A \given B} = \frac{\prob{A \cap B}}{\prob{B}}. 
\]

The conditional probability measures the probability that the event
$A$ occurs given that $B$ does.  It is defined only when $\prob{B} > 0$.
\end{definition}


\begin{flex}

\begin{gram}[Conditional Probability is a Probability Measure]
Conditional probability satisfies the three axioms of probability measures and thus itself a probability measure.
We can thus treat conditional probabilities just as ordinary
probabilities.  Intuitively, conditional probability can be thought as
a focusing and re-normalization of the probabilities on the
assumed event $B$.
%
\end{gram}

\begin{example}
Consider throwing two fair dice and calculate the probability that the
first dice comes us $1$ given that the sum of the two dice is $4$. 
%
Let $A$ be the event  that the first dice comes up $1$ and $B$ the
event that the sum is $4$.
%
We can write $A$ and $B$ in terms of outcomes as 
\[
\begin{array}{lll}
A & = & \{ (1,1), (1,2), (1,3), (1,4), (1,5), (1,6) \}~\mbox{and}
\\
B & = & \{ (1,3), (2,2), (3,1) \}.
\end{array}
\]
We thus have $A \cap B = \{ (1,3) \}$.
%
Since each outcome is equally likely, 
\[
\prob{A \given B} = \frac{\prob{A \cap B}}{\prob{B}} 
%
= 
%
\frac{|A \cap B|}{|B|} = \frac{1}{3}.
\]
\end{example}
\end{flex}

\subsection{Law of Total Probability}
\label{sec:probability::theory::LTP}

  
Conditional probabilities can be useful in estimating the probability
of an event that may depend on a selection of choices.
%
The total probability theorem can be handy in such circumstances.


\begin{flex}
\begin{theorem}[Law of Total Probability]
Consider a probabilistic space with sample space $\SSpace$ and let
$A_0, \ldots, A_{n-1}$ be a partition of $\SSpace$ such that $\prob{A_i} >
0$ for all $0 \le i < n$. 
%
For any event $B$ the following holds:
\[
\begin{array}{lll}
\prob{B} 
& = & \displaystyle\sum_{i=0}^{n-1} \prob{B \cap A_i}
\\
& = & 
\displaystyle\sum_{i=0}^{n-1} \prob{A_i}\prob{B  \given A_i}
\end{array}
\]
\end{theorem}

\begin{example}
Your favorite social network partitions your connections into two
kinds, near and far.
%
The social network has calculated that the probability that you react
to a post by one of your far connections is $0.1$ but the same
probability is $0.8$ for a post by one of your near connections.
%
Suppose that the social network shows you a post by a near and far
connection with probability $0.6$ and $0.4$ respectively. 
%

Let's calculate the probability that you react to a post that you see
on the network.
%
Let $A_0$ and $A_1$ be the event that the post is near and far
respectively.
%
We have $\prob{A_0} = 0.6$ and   $\prob{A_1} = 0.4$.
%
Let $B$ the event that you react, we know that  $\prob{B \given A_0} =
0.8$ and $\prob{B \given A_1} = 0.1$.
%

We want to calculate $\prob{B}$, which by total probability theorem we
know to be 
\[
\begin{array}{lll}
\prob{B} 
& = &   \prob{B \cap A_0} + \prob{B \cap  A_1} 
\\
& = &  \prob{A_0}\prob{B \given A_0} + \prob{A_1}\prob{B \given  A_1}. 
\\
& = &  0.6 \cdot 0.8 +  0.4 \cdot 0.1
\\
& = &  0.52.
\end{array}
\] 

\end{example}
\end{flex}

\subsection{Independence}
\label{sec:probability::theory::independence}

It is sometimes important to reason about the dependency relationship
between events.
%
Intuitively we say that two events are independent if  the occurrence
of one does not affect the probability of the other.
%
More precisely, we define independence as follows.  

  
\begin{definition}[Independence]
Two events $A$ and $B$ are \defn{independent}   if 
\[
\prob{A \cap B} = \prob{A} \cdot \prob{B}.
\]  
%
We say that multiple events $A_0, \dots, A_{n-1}$  are \defn{mutually
  independent} if and only if, for any non-empty subset $I \subseteq \{0, \dots, n-1\}$,
\[
\prob{\bigcap_{i \in I} A_i} = \prod_{i\in I} \prob{A_i}.
\]
\end{definition}

\begin{flex}

\begin{gram}[Independence and Conditional Probability]
Recall that  $\prob{A \given B} = \frac{\prob{A \cap
    B}}{\prob{B}}$ when $\prob{B} > 0$. Thus if $\prob{A \given B} = \prob{A}$ then
 $\prob{A \cap B} = \prob{A} \cdot \prob{B}$.
%
We can thus define independence in terms of conditional probability
but this works only when $\prob{B} > 0$. 
\end{gram}

\begin{example}
For two dice, the events $A = \csetf{(d_1,d_2) \in
  \SSpace}{d_1=1}$ (the first dice is 1) and $B = \csetf{(d_1,d_2) \in
  \SSpace}{d_2=1}$ (the second dice is 1) are independent since
%
\[
\begin{array}{llccl}\
& \prob{A} \times \prob{B} & = & \frac{1}{6} \times \frac{1}{6} & = \frac{1}{36} \\[4mm]
= & \prob{A \cap B} & = & \prob{\cset{(1,1)}} & = \frac{1}{36}~.
\end{array}
\]
%
However, the event $C \equiv \event{X}{4}$ (the dice add to 4) is not independent of $A$
since 
\[
\begin{array}{llccl}
& \prob{A} \times \prob{C} & = &\frac{1}{6} \times \frac{3}{36} & = \frac{1}{72} \\[4mm]
\neq & \prob{A \cap C} & = & \prob{\cset{(1,3)}} & = \frac{1}{36}~.
\end{array}
\]
$A$ and $C$ are not
independent since the fact that the first dice is 1 increases the
probability they sum to $4$ (from $\frac{1}{12}$ to $\frac{1}{6}$).

\end{example}
\end{flex}

\begin{exercise}
For two dice, let $A$ be the event that first roll is $1$ and $B$ be
the event that the sum of the rolls is $5$.
Are $A$ and $B$ independent?  Prove or disprove.

Consider now the same question but this time define $B$ to be the
event that the sum of the rolls is $7$.  
\end{exercise}


% \begin{simpleexample}
% Prove that disjoint events are never independent.
% \end{simpleexample}


% \begin{gram}
%   foo
% %
% \begin{notesonly}
% $\prob{A \given B} \ge 0$ holds because $\prob{A \cap B}$ is
% nonnegative.

% Given disjoint $A_0$ and $A_1$.
% \[
% \begin{array}{lll}

% \prob{(A_0 \cup A_1) \given B} & = & \prob{(A_0 \cup A_1) \cap B)} /
% \prob{B}
% \\[2mm]
% & = & \prob{(A_0 \cap B) \cup (A_1 \cap B)} / \prob{B}
% \\
% & = & \prob{(A_0 \cap B)} / \prob{B} +  \prob{(A_1 \cap B) \mbox(by
%   additivity because the two sets are disjoint}
% \\
% & = & ...
% \end{array}
% \]
% The final property holds trivially because $\SSpace \cap B = B$. 

% Thus conditional probabilities simple mass probabilities over the
% event $B$ that we are interested in. 

% \end{notesonly}


%
% \begin{notesonly}
% $\prob{A \given B} \ge 0$ holds because $\prob{A \cap B}$ is
% nonnegative.

% Given disjoint $A_0$ and $A_1$.
% \[
% \begin{array}{lll}

% \prob{(A_0 \cup A_1) \given B} & = & \prob{(A_0 \cup A_1) \cap B)} /
% \prob{B}
% \\[2mm]
% & = & \prob{(A_0 \cap B) \cup (A_1 \cap B)} / \prob{B}
% \\
% & = & \prob{(A_0 \cap B)} / \prob{B} +  \prob{(A_1 \cap B) \mbox(by
%   additivity because the two sets are disjoint}
% \\
% & = & ...
% \end{array}
% \]
% The final property holds trivially because $\SSpace \cap B = B$. 

% Thus conditional probabilities simple mass probabilities over the
% event $B$ that we are interested in. 

% \end{notesonly}
% \end{gram}

